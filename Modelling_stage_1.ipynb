{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "900a70b0-234e-4efa-bf11-a175eca4167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "# Bag of words and Tokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Classification methods\n",
    "from sklearn.naive_bayes import MultinomialNB   # Naive Bayes\n",
    "from sklearn.tree import DecisionTreeClassifier  # Decision Tree\n",
    "from sklearn.neural_network import MLPClassifier # Multi-Layer Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNN\n",
    "\n",
    "\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdcd761-3a63-4283-9c7b-05b52089d79b",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57ce024a-f820-4566-8fb0-6c6e14e5331e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>27</td>\n",
       "      <td>eebbqej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>27</td>\n",
       "      <td>ed00q6i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>2</td>\n",
       "      <td>eezlygj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>14</td>\n",
       "      <td>ed7ypvh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>3</td>\n",
       "      <td>ed0bdzj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label       id\n",
       "0  My favourite food is anything I didn't have to...    27  eebbqej\n",
       "1  Now if he does off himself, everyone will thin...    27  ed00q6i\n",
       "2                     WHY THE FUCK IS BAYLESS ISOING     2  eezlygj\n",
       "3                        To make her feel threatened    14  ed7ypvh\n",
       "4                             Dirty Southern Wankers     3  ed0bdzj"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'Full_dataset/'\n",
    "rdfTrain = pd.read_csv(data_path + 'train.tsv', sep = '\\t', header = None, names = ['text', 'label', 'id'])\n",
    "rdfTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6feb98-2530-4cda-9af6-a3699ebf9a38",
   "metadata": {},
   "source": [
    "Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5ee46521-ddea-4922-9cd9-49a4b738ebf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5426 entries, 0 to 5425\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5426 non-null   object\n",
      " 1   label   5426 non-null   object\n",
      " 2   id      5426 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 127.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# validation set\n",
    "data_path = 'Full_dataset/'\n",
    "rdfDev = pd.read_csv(data_path + 'dev.tsv', sep = '\\t', header = None, names = ['text', 'label', 'id'])\n",
    "rdfDev.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6f734c-25ae-4cb5-afcb-0a940fa7f260",
   "metadata": {},
   "source": [
    "Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "32037543-8f1e-432a-9282-c7b7040ae522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5427 entries, 0 to 5426\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    5427 non-null   object\n",
      " 1   label   5427 non-null   object\n",
      " 2   id      5427 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 127.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# test set\n",
    "data_path = 'Full_dataset/'\n",
    "rdfTest = pd.read_csv(data_path + 'test.tsv', sep = '\\t', header = None, names = ['text', 'label', 'id'])\n",
    "rdfTest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35b7b6dd-a201-4541-8e19-99de59c6658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_neutral(row):\n",
    "    if row['label'] == '27':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d51b80c5-dff8-4e76-8243-19c8dde05fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_labels = ['admiration','approval', 'amusement', 'caring', 'desire', \n",
    "              'excitement', 'gratitude', 'joy', 'love','optimism', 'pride', 'relief']\n",
    "neg_labels = ['anger', 'annoyance', 'disappointment', 'disapproval', 'disgust',\n",
    "              'embarrassment','fear', 'grief', 'nervousness', 'remorse', 'sadness']\n",
    "ambi_labels = ['confusion', 'curiosity', 'realization', 'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "71842ba6-4ffa-4c90-a444-70f5aeaa23b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_to_idx = {\n",
    "    'admiration' : '0',\n",
    "    'amusement' : '1',\n",
    "    'anger' : '2',\n",
    "    'annoyance' : '3',\n",
    "    'approval' : '4',\n",
    "    'caring' : '5',\n",
    "    'confusion' : '6',\n",
    "    'curiosity' : '7',\n",
    "    'desire' : '8',\n",
    "    'disappointment' : '9',\n",
    "    'disapproval' : '10',\n",
    "    'disgust' : '11',\n",
    "    'embarrassment' : '12',\n",
    "    'excitement' : '13',\n",
    "    'fear' : '14',\n",
    "    'gratitude' : '15',\n",
    "    'grief' : '16',\n",
    "    'joy' : '17',\n",
    "    'love' : '18',\n",
    "    'nervousness' : '19',\n",
    "    'optimism' : '20',\n",
    "    'pride' : '21',\n",
    "    'realization' : '22',\n",
    "    'relief' : '23',\n",
    "    'remorse' : '24',\n",
    "    'sadness' : '25',\n",
    "    'surprise' : '26',\n",
    "    'neutral' : '27'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "396469ee-241a-47e7-a17c-28e3d1822cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'admiration',\n",
       " '1': 'amusement',\n",
       " '2': 'anger',\n",
       " '3': 'annoyance',\n",
       " '4': 'approval',\n",
       " '5': 'caring',\n",
       " '6': 'confusion',\n",
       " '7': 'curiosity',\n",
       " '8': 'desire',\n",
       " '9': 'disappointment',\n",
       " '10': 'disapproval',\n",
       " '11': 'disgust',\n",
       " '12': 'embarrassment',\n",
       " '13': 'excitement',\n",
       " '14': 'fear',\n",
       " '15': 'gratitude',\n",
       " '16': 'grief',\n",
       " '17': 'joy',\n",
       " '18': 'love',\n",
       " '19': 'nervousness',\n",
       " '20': 'optimism',\n",
       " '21': 'pride',\n",
       " '22': 'realization',\n",
       " '23': 'relief',\n",
       " '24': 'remorse',\n",
       " '25': 'sadness',\n",
       " '26': 'surprise',\n",
       " '27': 'neutral'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_emotion = {j:i for i, j in emotion_to_idx.items()}\n",
    "label_to_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e7ce04c-dcaf-4b06-85f3-58d60e0af945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_pos_neg_neutral(row):\n",
    "    '''\n",
    "    Sentiment Analysis label:\n",
    "    0 - Negative\n",
    "    1 - Positive\n",
    "    2 - Neutral/Ambigous\n",
    "    '''\n",
    "    sentiment = [0, 0, 0]\n",
    "    labels = str(row['label']).split(\",\")\n",
    "    for l in labels:\n",
    "        label = label_to_emotion[l] \n",
    "        if label in pos_labels:\n",
    "            sentiment[1] += 1\n",
    "        elif label in neg_labels:\n",
    "            sentiment[0] += 1\n",
    "        else:\n",
    "            sentiment[2] += 1\n",
    "    return np.argmax(np.array(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c7dcd102-98ca-405e-bd27-b98766f26dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "anger_list = [ \"anger\", \"annoyance\", \"disapproval\", \"disgust\"]\n",
    "fear_list = [\"fear\", \"nervousness\"]\n",
    "joy_list = [\"joy\", \"amusement\", \"approval\", \"excitement\", \"gratitude\",\"love\", \"optimism\", \"relief\", \"pride\", \"admiration\", \"desire\", \"caring\"]\n",
    "sadness_list = [\"sadness\", \"disappointment\", \"embarrassment\", \"grief\", \"remorse\"]\n",
    "surprise_list = [\"surprise\", \"realization\", \"confusion\", \"curiosity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5672d841-5a53-4bc3-98a4-c8a3b4fae704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_emotion_group(row):\n",
    "    '''\n",
    "    Groupping Emotion Label:\n",
    "    0 - Anger, 1 - Fear, 2- Joy, \n",
    "    3 - Sadness, 4 - Surprise, 5 - Neutral/Ambigous\n",
    "    '''\n",
    "    sentiment = [0]*6\n",
    "    labels = str(row['label']).split(\",\")\n",
    "    for l in labels:\n",
    "        if l == '27': \n",
    "            return 5 # Neutral\n",
    "        \n",
    "        label = label_to_emotion[l]\n",
    "        if label in anger_list:\n",
    "            sentiment[0] += 1\n",
    "        elif label in fear_list:\n",
    "            sentiment[1] += 1\n",
    "        elif label in joy_list:\n",
    "            sentiment[2] += 1\n",
    "        elif label in sadness_list:\n",
    "            sentiment[3] += 1\n",
    "        elif label in surprise_list:\n",
    "            sentiment[4] += 1\n",
    "        else:\n",
    "            sentiment[5] += 1\n",
    "    return np.argmax(np.array(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7abc1fe-b3e1-4319-acb5-b8e4f786c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = {\n",
    "    '0' :  '0', # admiration, desire\n",
    "    '10' :  '1', # disapproval, disgust, disappointment, embarrassment \n",
    "    '2' : '2',  # anger, annoyance \n",
    "    '13' : '3', # excitement, amusement\n",
    "    '18' : '4', # love, caring\n",
    "    '4' : '5',  # approval\n",
    "    '15' : '6', # gratitude\n",
    "    '7' : '7',  # curiosity\n",
    "    '25' : '8', # sadness , grief, remorse \n",
    "    '17' : '9', # joy , pride, relief\n",
    "    '20' : '10', # optimism\n",
    "    '6' : '11', # confusion\n",
    "    '22' : '12', # realization\n",
    "    '26' : '13', # surprise\n",
    "    '14' :  '14' # fear, nervousness\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d5d5f52-12ec-4a39-9423-af7660a7f283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignoring neutral and merging emotions \n",
    "def multi_class(df):\n",
    "    data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        labels = str(row['label']).split(\",\")\n",
    "        for l in labels:\n",
    "            l_txt = label_to_emotion[l]\n",
    "            if l_txt == 'neutral':\n",
    "                continue\n",
    "            elif l_txt == 'desire':\n",
    "                l = emotion_to_idx['admiration']\n",
    "            elif l_txt == 'amusement':\n",
    "                l = emotion_to_idx['excitement']\n",
    "            elif l_txt == 'pride' or l_txt == 'relief':\n",
    "                l = emotion_to_idx['joy']\n",
    "            elif l_txt == 'caring':\n",
    "                l = emotion_to_idx['love']\n",
    "            elif l_txt == 'embarrassment' or l_txt == 'disgust' or l_txt == 'disappointment':\n",
    "                l = emotion_to_idx['disapproval']\n",
    "            elif l_txt == 'nervousness':\n",
    "                l = emotion_to_idx['fear']\n",
    "            elif l_txt == 'remorse' or l_txt == 'grief':\n",
    "                l = emotion_to_idx['sadness']\n",
    "            elif l_txt == 'annoyance':\n",
    "                l = emotion_to_idx['anger']\n",
    "            idx = label_idx[l]\n",
    "            data.append([row['text'],idx])\n",
    "    data = np.array(data)\n",
    "    new_df = pd.DataFrame(data=data, columns=['text','labels'])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bfb11c43-5cef-4838-9221-b046ed9ed35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_label(df):\n",
    "    data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        labels = str(row['label']).split(\",\")\n",
    "        for l in labels:\n",
    "            data.append([row['text'],l])\n",
    "    data = np.array(data)\n",
    "    new_df = pd.DataFrame(data=data, columns=['text','labels'])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "699121a1-108d-4b94-ab57-65503f197fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformData(rdfTrain, rdfDev, rdfTest, n_categories = 2):\n",
    "    \n",
    "    dfTrain, dfDev, dfTest = rdfTrain, rdfDev, rdfTest\n",
    "    if n_categories == 2:\n",
    "        dfTrain[\"labels\"] = dfTrain.apply(lambda row: label_neutral(row), axis = 1)\n",
    "        dfDev[\"labels\"] = dfDev.apply(lambda row: label_neutral(row), axis = 1)\n",
    "        dfTest[\"labels\"] = dfTest.apply(lambda row: label_neutral(row), axis = 1)\n",
    "    \n",
    "    if n_categories == 3:\n",
    "        dfTrain[\"labels\"] = dfTrain.apply(lambda row: label_pos_neg_neutral(row), axis = 1)\n",
    "        dfDev[\"labels\"] = dfDev.apply(lambda row: label_pos_neg_neutral(row), axis = 1)\n",
    "        dfTest[\"labels\"] = dfTest.apply(lambda row: label_pos_neg_neutral(row), axis = 1)\n",
    "        \n",
    "    if n_categories == 6:\n",
    "        dfTrain[\"labels\"] = dfTrain.apply(lambda row: label_emotion_group(row), axis = 1)\n",
    "        dfDev[\"labels\"] = dfDev.apply(lambda row: label_emotion_group(row), axis = 1)\n",
    "        dfTest[\"labels\"] = dfTest.apply(lambda row: label_emotion_group(row), axis = 1)\n",
    "    \n",
    "    if n_categories == 28:\n",
    "        dfTrain = multi_class(dfTrain)\n",
    "        print(dfTrain.head())\n",
    "        dfDev = multi_class(dfDev)\n",
    "        dfTest = multi_class(dfTest)\n",
    "    \n",
    "    print(\"Training distribution: \", dfTrain.labels.value_counts())\n",
    "    print(\"Dev data distribution: \", dfDev.labels.value_counts())\n",
    "    print(\"Test data distribution: \", dfTest.labels.value_counts())\n",
    "        \n",
    "    return dfTrain, dfDev, dfTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cccaf8ca-1020-4448-b962-312a301392e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  labels\n",
      "0    30587\n",
      "1    12823\n",
      "Name: count, dtype: int64\n",
      "Dev data distribution:  labels\n",
      "0    3834\n",
      "1    1592\n",
      "Name: count, dtype: int64\n",
      "Test data distribution:  labels\n",
      "0    3821\n",
      "1    1606\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTrain, dfDev, dfTest = transformData(rdfTrain, rdfDev, rdfTest, n_categories = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ddbbfc1b-b218-4e24-a635-1b40eebee196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  labels\n",
      "2    17021\n",
      "1    16628\n",
      "0     9761\n",
      "Name: count, dtype: int64\n",
      "Dev data distribution:  labels\n",
      "1    2106\n",
      "2    2096\n",
      "0    1224\n",
      "Name: count, dtype: int64\n",
      "Test data distribution:  labels\n",
      "2    2147\n",
      "1    2026\n",
      "0    1254\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTrain, dfDev, dfTest = transformData(rdfTrain, rdfDev, rdfTest, n_categories = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f2b366f-ed2c-4cc2-92cf-4951ffd96eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  labels\n",
      "2    16327\n",
      "5    14219\n",
      "0     5829\n",
      "4     3888\n",
      "3     2489\n",
      "1      658\n",
      "Name: count, dtype: int64\n",
      "Dev data distribution:  labels\n",
      "2    2067\n",
      "5    1766\n",
      "0     748\n",
      "4     466\n",
      "3     289\n",
      "1      90\n",
      "Name: count, dtype: int64\n",
      "Test data distribution:  labels\n",
      "2    1977\n",
      "5    1787\n",
      "0     777\n",
      "4     494\n",
      "3     304\n",
      "1      88\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTrain, dfDev, dfTest = transformData(rdfTrain, rdfDev, rdfTest, n_categories = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "643998af-f7e1-44a9-98cc-e314fd7178b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text labels\n",
      "0                     WHY THE FUCK IS BAYLESS ISOING      2\n",
      "1                        To make her feel threatened     14\n",
      "2                             Dirty Southern Wankers      2\n",
      "3  OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...     13\n",
      "4  Yes I heard abt the f bombs! That has to be wh...      6\n",
      "Training distribution:  labels\n",
      "0     4771\n",
      "1     4387\n",
      "2     4037\n",
      "3     3181\n",
      "4     3173\n",
      "5     2939\n",
      "6     2662\n",
      "7     2191\n",
      "8     1948\n",
      "9     1716\n",
      "10    1581\n",
      "11    1368\n",
      "12    1110\n",
      "13    1060\n",
      "14     760\n",
      "Name: count, dtype: int64\n",
      "Dev data distribution:  labels\n",
      "1     587\n",
      "0     565\n",
      "2     498\n",
      "4     405\n",
      "3     399\n",
      "5     397\n",
      "6     358\n",
      "7     248\n",
      "8     224\n",
      "10    209\n",
      "9     205\n",
      "11    152\n",
      "13    129\n",
      "12    127\n",
      "14    111\n",
      "Name: count, dtype: int64\n",
      "Test data distribution:  labels\n",
      "0     587\n",
      "1     578\n",
      "2     518\n",
      "4     373\n",
      "3     367\n",
      "6     352\n",
      "5     351\n",
      "7     284\n",
      "8     218\n",
      "9     188\n",
      "10    186\n",
      "11    153\n",
      "12    145\n",
      "13    141\n",
      "14    101\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTrain, dfDev, dfTest = transformData(rdfTrain, rdfDev, rdfTest, n_categories = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e0b98d5-218b-4f55-8e39-0ca2642d3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrain = dfTrain[['text', 'labels']]\n",
    "dfDev = dfDev[['text', 'labels']]\n",
    "dfTest = dfTest[['text', 'labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "480441a3-eea3-4750-bd95-0521ff837140",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'Data/'\n",
    "dfTrain.to_csv(data_path + 'train.tsv', sep='\\t', header=False, index=False)\n",
    "dfDev.to_csv(data_path + 'dev.tsv', sep='\\t', header=False, index=False)\n",
    "dfTest.to_csv(data_path + 'test.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca916071-5823-4a58-a54c-98e8a9c2cda3",
   "metadata": {},
   "source": [
    "Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "17e22e10-0723-4e9b-9b85-8d8066251fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(trainFeatures, devFeatures, dfTrain, dfDev):\n",
    "    xTrain, yTrain = trainFeatures, dfTrain['labels']\n",
    "    xDev, yDev = devFeatures, dfDev['labels']\n",
    "    \n",
    "    print(\"Dev : \", xDev.shape, yDev.shape)\n",
    "    print(\"Train : \", xTrain.shape, yTrain.shape)\n",
    "    \n",
    "    return xTrain, yTrain, xDev, yDev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3bfd3f-e2c4-4f41-878c-fbaeb87c49d5",
   "metadata": {},
   "source": [
    "TF-IDF & Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3cfd0f8f-1e85-4e62-85bb-9adfacc6b723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureGeneration(dfTrain, dfDev, method = 'BOW'):\n",
    "    if method == 'BOW':\n",
    "        #tokenizer to remove unwanted elements from out data like symbols and numbers\n",
    "        #token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "        token = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "        cv = CountVectorizer(lowercase=True, stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "        trainFeatures = cv.fit_transform(dfTrain['text'])\n",
    "        devFeatures = cv.transform(dfDev['text'])\n",
    "    \n",
    "    if method == 'TF-IDF':\n",
    "        tf = TfidfVectorizer()\n",
    "        trainFeatures = tf.fit_transform(dfTrain['text'])\n",
    "        devFeatures = tf.transform(dfDev['text'])\n",
    "        \n",
    "    return trainFeatures, devFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ac809-01c4-46ed-95e2-f94778560bd6",
   "metadata": {},
   "source": [
    "Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b580b459-6493-4b71-85ae-f84b457b728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(xTrain, yTrain, xDev, yDev):\n",
    "    # Model Generation Using Multinomial Naive Bayes\n",
    "    clf = MultinomialNB().fit(xTrain, yTrain)\n",
    "    predicted= clf.predict(xDev)\n",
    "    print(\"MultinomialNB Accuracy:\", metrics.accuracy_score(yDev, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4a537905-7b25-4035-a952-358baef09a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xTrain, yTrain, xDev, yDev, method = 'Naive Bayes'):\n",
    "    \n",
    "    num_classes = len(yTrain.unique())\n",
    "    print(\"Num classes: \", num_classes)\n",
    "    \n",
    "    if method == 'Naive Bayes':\n",
    "        clf = MultinomialNB()\n",
    "    \n",
    "    if method == 'Decision Trees':\n",
    "        clf = DecisionTreeClassifier()\n",
    "\n",
    "    if method == 'MLP':\n",
    "        clf = MLPClassifier()\n",
    "    \n",
    "    if method == 'KNN':\n",
    "        clf = KNeighborsClassifier(n_neighbors=5)\n",
    "        \n",
    "    clf = clf.fit(xTrain, yTrain)\n",
    "    predicted= clf.predict(xDev)\n",
    "    \n",
    "#   Evaluation metrics\n",
    "\n",
    "    Y_test = label_binarize(yDev, classes=[0, 1, 2])\n",
    "    Y_score = label_binarize(predicted, classes=[0, 1, 2])\n",
    "    \n",
    "    \n",
    "    target_names = [str(i) for i in range(num_classes)]\n",
    "    print(classification_report(yDev, predicted, target_names=target_names))\n",
    "    acc = metrics.accuracy_score(Y_test, Y_score)\n",
    "    precision = metrics.precision_score(Y_test, Y_score, average='macro')\n",
    "    recall = metrics.recall_score(Y_test, Y_score,average='macro' )\n",
    "    #roc_auc = metrics.roc_auc_score(Y_test, Y_score,average='macro')\n",
    "    f1 = metrics.f1_score(Y_test, Y_score, average='macro')\n",
    "    confusion_matrix = metrics.confusion_matrix(yDev, predicted)\n",
    "\n",
    "    #print(str(acc) + \"\\t\" + str(precision) + \"\\t\" + str(recall) + \"\\t\" + str(f1) + \"\\t\" + str(roc_auc))\n",
    "    print(str(acc) + \"\\t\" + str(precision) + \"\\t\" + str(recall) + \"\\t\" + str(f1))\n",
    "    print(confusion_matrix)\n",
    "        \n",
    "    print(\"Accuracy:\", acc)\n",
    "    #     print(\"Precision:\", precision)\n",
    "    #     print(\"Recall:\", recall)\n",
    "    #     print(\"ROC AUC: \", roc_auc)\n",
    "    #     print(\"f1-score:\", f1)\n",
    "    #     print(\"Confusion Matrix: \\n\", confusion_matrix)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33311ac8-f4a0-4b5f-957b-e8bf3ab50c36",
   "metadata": {},
   "source": [
    "Grouping emotions to 3 - Naive Bayes, DT, MLP, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5369c11d-bf89-41f5-9ffe-9d3058aa9d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  labels\n",
      "2    17021\n",
      "1    16628\n",
      "0     9761\n",
      "Name: count, dtype: int64\n",
      "Dev data distribution:  labels\n",
      "1    2106\n",
      "2    2096\n",
      "0    1224\n",
      "Name: count, dtype: int64\n",
      "Test data distribution:  labels\n",
      "2    2147\n",
      "1    2026\n",
      "0    1254\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTrain, dfDev, dfTest = transformData(rdfTrain, rdfDev, rdfTest, n_categories = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "945fadc5-da68-42d1-ac25-61968a49fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev :  (5426, 27774) (5426,)\n",
      "Train :  (43410, 27774) (43410,)\n"
     ]
    }
   ],
   "source": [
    "trainFeatures, devFeatures = featureGeneration(dfTrain, dfDev, method = 'BOW')\n",
    "xTrain, yTrain, xDev, yDev = splitData(trainFeatures, devFeatures, dfTrain, dfDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5450f7f2-38dc-42ac-ae0f-d0880daf3e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.42      0.50      1224\n",
      "           1       0.67      0.78      0.72      2106\n",
      "           2       0.63      0.64      0.63      2096\n",
      "\n",
      "    accuracy                           0.64      5426\n",
      "   macro avg       0.64      0.61      0.62      5426\n",
      "weighted avg       0.64      0.64      0.64      5426\n",
      "\n",
      "0.6444894950239587\t0.6350129472893912\t0.6132510170796605\t0.6174241641027124\t0.7134700171986642\n",
      "[[ 515  273  436]\n",
      " [ 107 1637  362]\n",
      " [ 231  520 1345]]\n",
      "Accuracy: 0.6444894950239587\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88b0d69c-feb9-4614-8b1c-41d057ecfbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.45      0.47      1224\n",
      "           1       0.70      0.69      0.70      2106\n",
      "           2       0.60      0.64      0.62      2096\n",
      "\n",
      "    accuracy                           0.62      5426\n",
      "   macro avg       0.60      0.59      0.59      5426\n",
      "weighted avg       0.61      0.62      0.61      5426\n",
      "\n",
      "0.6162919277552524\t0.5984983702851232\t0.5927899425068013\t0.5949064650316477\t0.6977563793690509\n",
      "[[ 548  236  440]\n",
      " [ 177 1462  467]\n",
      " [ 368  394 1334]]\n",
      "Accuracy: 0.6162919277552524\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'Decision Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a6ffb97-527f-4ecc-9ef3-2afccc722acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.48      0.52      1224\n",
      "           1       0.72      0.72      0.72      2106\n",
      "           2       0.63      0.68      0.65      2096\n",
      "\n",
      "    accuracy                           0.65      5426\n",
      "   macro avg       0.64      0.63      0.63      5426\n",
      "weighted avg       0.65      0.65      0.65      5426\n",
      "\n",
      "0.6516771102100996\t0.6366019399760511\t0.6281485369134424\t0.631184819132013\t0.7242738440035495\n",
      "[[ 591  217  416]\n",
      " [ 157 1525  424]\n",
      " [ 313  363 1420]]\n",
      "Accuracy: 0.6516771102100996\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d68bff4d-d1c0-4356-a94b-01cf85dee5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.25      0.31      1224\n",
      "           1       0.66      0.51      0.58      2106\n",
      "           2       0.50      0.72      0.59      2096\n",
      "\n",
      "    accuracy                           0.53      5426\n",
      "   macro avg       0.52      0.49      0.49      5426\n",
      "weighted avg       0.54      0.53      0.52      5426\n",
      "\n",
      "0.5333579063767048\t0.5179227356682982\t0.49409991808210635\t0.4909140688000709\t0.6251523304782824\n",
      "[[ 306  226  692]\n",
      " [ 220 1074  812]\n",
      " [ 253  329 1514]]\n",
      "Accuracy: 0.5333579063767048\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef8b4a8-d8a0-4442-92bb-0b4c87eba6c2",
   "metadata": {},
   "source": [
    "Grouping emotions into 6 - Naive Bayes, DT, MLP, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9a7d4a69-64a9-461f-87c9-0c83b56d21a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training distribution:  labels\n",
      "2    16327\n",
      "5    14219\n",
      "0     5829\n",
      "4     3888\n",
      "3     2489\n",
      "1      658\n",
      "Name: count, dtype: int64\n",
      "Dev data distribution:  labels\n",
      "2    2067\n",
      "5    1766\n",
      "0     748\n",
      "4     466\n",
      "3     289\n",
      "1      90\n",
      "Name: count, dtype: int64\n",
      "Test data distribution:  labels\n",
      "2    1977\n",
      "5    1787\n",
      "0     777\n",
      "4     494\n",
      "3     304\n",
      "1      88\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTrain, dfDev, dfTest = transformData(rdfTrain, rdfDev, rdfTest, n_categories = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4a87015a-87b9-45d1-95b7-3c943d63236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev :  (5426, 27774) (5426,)\n",
      "Train :  (43410, 27774) (43410,)\n"
     ]
    }
   ],
   "source": [
    "trainFeatures, devFeatures = featureGeneration(dfTrain, dfDev, method = 'BOW')\n",
    "xTrain, yTrain, xDev, yDev = splitData(trainFeatures, devFeatures, dfTrain, dfDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b3a6df4c-9689-486d-9472-a8fe096c0301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.27      0.36       748\n",
      "           1       1.00      0.01      0.02        90\n",
      "           2       0.60      0.83      0.70      2067\n",
      "           3       0.63      0.09      0.16       289\n",
      "           4       0.56      0.12      0.19       466\n",
      "           5       0.51      0.58      0.54      1766\n",
      "\n",
      "    accuracy                           0.56      5426\n",
      "   macro avg       0.64      0.32      0.33      5426\n",
      "weighted avg       0.56      0.56      0.52      5426\n",
      "\n",
      "0.6291927755252488\t0.7139981126140297\t0.37263246885888396\t0.3603987969531645\t0.6224049948391865\n",
      "[[ 204    0  222    4    7  311]\n",
      " [  12    1   41    1    2   33]\n",
      " [  25    0 1724    2    6  310]\n",
      " [  13    0  137   27    0  112]\n",
      " [  18    0  160    1   54  233]\n",
      " [ 102    0  606    8   28 1022]]\n",
      "Accuracy: 0.6291927755252488\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "268b0058-afc4-4fa5-bd91-13b9263583d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.35      0.37       748\n",
      "           1       0.43      0.26      0.32        90\n",
      "           2       0.69      0.71      0.70      2067\n",
      "           3       0.45      0.36      0.40       289\n",
      "           4       0.41      0.39      0.40       466\n",
      "           5       0.52      0.56      0.54      1766\n",
      "\n",
      "    accuracy                           0.56      5426\n",
      "   macro avg       0.48      0.44      0.45      5426\n",
      "weighted avg       0.55      0.56      0.55      5426\n",
      "\n",
      "0.6391448580906746\t0.5021654666184694\t0.4380319314836518\t0.4625710230531997\t0.6707497415247259\n",
      "[[ 262    9  147   28   43  259]\n",
      " [  15   23   18    2    5   27]\n",
      " [ 101    7 1464   42   64  389]\n",
      " [  41    1   50  104    7   86]\n",
      " [  37    6   76    7  181  159]\n",
      " [ 213    8  370   48  143  984]]\n",
      "Accuracy: 0.6391448580906746\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'Decision Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a86777f5-6ba9-4be9-8f16-1786f43c2469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.42      0.44       748\n",
      "           1       0.47      0.47      0.47        90\n",
      "           2       0.70      0.73      0.71      2067\n",
      "           3       0.46      0.40      0.43       289\n",
      "           4       0.39      0.33      0.36       466\n",
      "           5       0.53      0.55      0.54      1766\n",
      "\n",
      "    accuracy                           0.57      5426\n",
      "   macro avg       0.50      0.48      0.49      5426\n",
      "weighted avg       0.57      0.57      0.57      5426\n",
      "\n",
      "0.6607077036490969\t0.5403835431682017\t0.5401689998249376\t0.5400464512075439\t0.7227040943988747\n",
      "[[ 317   15  125   23   35  233]\n",
      " [  10   42   17    2    2   17]\n",
      " [  99   12 1509   49   49  349]\n",
      " [  40    4   45  115   14   71]\n",
      " [  32    4   74   14  155  187]\n",
      " [ 208   12  385   47  143  971]]\n",
      "Accuracy: 0.6607077036490969\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8d4706b9-bc45-4f78-94c5-5ebc074a515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.18      0.24       748\n",
      "           1       0.40      0.02      0.04        90\n",
      "           2       0.65      0.53      0.59      2067\n",
      "           3       0.51      0.12      0.20       289\n",
      "           4       0.39      0.21      0.28       466\n",
      "           5       0.42      0.70      0.52      1766\n",
      "\n",
      "    accuracy                           0.48      5426\n",
      "   macro avg       0.45      0.30      0.31      5426\n",
      "weighted avg       0.50      0.48      0.46      5426\n",
      "\n",
      "0.5842241061555473\t0.46054222797866\t0.2463336371771444\t0.2881349944169438\t0.5838940121498468\n",
      "[[ 137    0  152    8   17  434]\n",
      " [   5    2   17    1    6   59]\n",
      " [ 103    1 1103   16   28  816]\n",
      " [  14    1   55   35    7  177]\n",
      " [  35    0   70    3  100  258]\n",
      " [ 121    1  296    5  100 1243]]\n",
      "Accuracy: 0.5842241061555473\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca99315-e9ab-4581-b82c-3daabcbebde8",
   "metadata": {},
   "source": [
    "Grouping emotions into 28 - Naive Bayes, DT, MLP, KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3503fd7f-f66b-4de9-bdbe-08bd6eb8abe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text labels\n",
      "0                     WHY THE FUCK IS BAYLESS ISOING      2\n",
      "1                        To make her feel threatened     14\n",
      "2                             Dirty Southern Wankers      2\n",
      "3  OmG pEyToN iSn'T gOoD eNoUgH tO hElP uS iN tHe...     13\n",
      "4  Yes I heard abt the f bombs! That has to be wh...      6\n",
      "Training distribution:  labels\n",
      "0     4771\n",
      "1     4387\n",
      "2     4037\n",
      "3     3181\n",
      "4     3173\n",
      "5     2939\n",
      "6     2662\n",
      "7     2191\n",
      "8     1948\n",
      "9     1716\n",
      "10    1581\n",
      "11    1368\n",
      "12    1110\n",
      "13    1060\n",
      "14     760\n",
      "Name: count, dtype: int64\n",
      "Dev data distribution:  labels\n",
      "1     587\n",
      "0     565\n",
      "2     498\n",
      "4     405\n",
      "3     399\n",
      "5     397\n",
      "6     358\n",
      "7     248\n",
      "8     224\n",
      "10    209\n",
      "9     205\n",
      "11    152\n",
      "13    129\n",
      "12    127\n",
      "14    111\n",
      "Name: count, dtype: int64\n",
      "Test data distribution:  labels\n",
      "0     587\n",
      "1     578\n",
      "2     518\n",
      "4     373\n",
      "3     367\n",
      "6     352\n",
      "5     351\n",
      "7     284\n",
      "8     218\n",
      "9     188\n",
      "10    186\n",
      "11    153\n",
      "12    145\n",
      "13    141\n",
      "14    101\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dfTrain, dfDev, dfTest = transformData(rdfTrain, rdfDev, rdfTest, n_categories = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ea27c73f-f3c5-4e95-acea-63ef45d21bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev :  (4614, 21975) (4614,)\n",
      "Train :  (36884, 21975) (36884,)\n"
     ]
    }
   ],
   "source": [
    "trainFeatures, devFeatures = featureGeneration(dfTrain, dfDev, method = 'BOW')\n",
    "xTrain, yTrain, xDev, yDev = splitData(trainFeatures, devFeatures, dfTrain, dfDev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "10189128-507e-47a2-b14c-1588b99bce51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.73      0.48       565\n",
      "           1       0.31      0.56      0.40       587\n",
      "           2       0.52      0.12      0.20       209\n",
      "           3       0.52      0.07      0.13       152\n",
      "           4       0.50      0.01      0.02       127\n",
      "           5       0.50      0.03      0.06       129\n",
      "           6       0.75      0.05      0.10       111\n",
      "           7       0.43      0.51      0.47       498\n",
      "           8       0.53      0.51      0.52       399\n",
      "           9       0.50      0.49      0.49       405\n",
      "          10       0.34      0.18      0.24       397\n",
      "          11       0.67      0.70      0.68       358\n",
      "          12       0.57      0.40      0.47       248\n",
      "          13       0.64      0.37      0.47       224\n",
      "          14       0.49      0.10      0.16       205\n",
      "\n",
      "    accuracy                           0.43      4614\n",
      "   macro avg       0.51      0.32      0.33      4614\n",
      "weighted avg       0.47      0.43      0.39      4614\n",
      "\n",
      "1.0\t0.0\t0.0\t0.0\n",
      "[[412  48   3   0   0   1   0  14  17  27  11  23   4   2   3]\n",
      " [ 75 331   1   1   0   1   1  92  18  25  24   6   1  10   1]\n",
      " [ 77  35  26   0   0   0   0  10  10  18  11  14   0   7   1]\n",
      " [ 12  52   2  11   0   0   0  21   7   5  11   2  28   1   0]\n",
      " [ 29  41   0   1   1   0   0  15  13   8   9   7   2   1   0]\n",
      " [ 32  31   1   0   0   4   0  21  16   5   5   6   8   0   0]\n",
      " [ 17  45   1   0   0   0   6  17   1   9   8   1   4   2   0]\n",
      " [ 32 145   1   1   0   0   0 252  16  18  10   9   9   5   0]\n",
      " [ 67  50   1   1   0   2   0  29 202  17   7  11   6   0   6]\n",
      " [ 86  49   5   1   0   0   0  15   7 198  15  13   8   8   0]\n",
      " [104 108   3   0   1   0   0  33  26  23  72  14   4   5   4]\n",
      " [ 69   6   1   0   0   0   1   8   8   8   3 250   0   1   3]\n",
      " [ 37  40   0   3   0   0   0  39  10   4   9   1  99   3   3]\n",
      " [ 30  72   2   2   0   0   0  10   4  13   5   4   0  82   0]\n",
      " [ 80  30   3   0   0   0   0   6  24  18   9  14   0   1  20]]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'Naive Bayes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "870834e7-26f8-46f7-9f34-3040abee491f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.59      0.50       565\n",
      "           1       0.35      0.43      0.39       587\n",
      "           2       0.42      0.44      0.43       209\n",
      "           3       0.31      0.33      0.32       152\n",
      "           4       0.19      0.13      0.15       127\n",
      "           5       0.36      0.38      0.37       129\n",
      "           6       0.55      0.33      0.42       111\n",
      "           7       0.42      0.36      0.39       498\n",
      "           8       0.55      0.51      0.53       399\n",
      "           9       0.48      0.50      0.49       405\n",
      "          10       0.28      0.21      0.24       397\n",
      "          11       0.80      0.72      0.76       358\n",
      "          12       0.46      0.54      0.50       248\n",
      "          13       0.54      0.46      0.50       224\n",
      "          14       0.38      0.26      0.31       205\n",
      "\n",
      "    accuracy                           0.44      4614\n",
      "   macro avg       0.43      0.41      0.42      4614\n",
      "weighted avg       0.44      0.44      0.44      4614\n",
      "\n",
      "1.0\t0.0\t0.0\t0.0\n",
      "[[336  36  26   3   5  13   1  18  15  37  23  11  18   7  16]\n",
      " [ 64 250  14  15  13  13   7  67  23  25  47   3  13  22  11]\n",
      " [ 33  24  91   2   4   1   0   6  11  12  12   4   4   1   4]\n",
      " [  7  25   4  50   2   2   2   6   7   1  10   0  35   1   0]\n",
      " [ 16  26   3   6  16   6   1   9   5   8  13   3   6   8   1]\n",
      " [ 10  16   2   5   2  49   1  13   7   4   2   7   5   4   2]\n",
      " [  8  17   2   2   0   4  37  10   0  11  14   1   4   0   1]\n",
      " [ 37 115   6  22   9  12   3 177  16  24  27   4  29  11   6]\n",
      " [ 35  30   4   9   4  18   0  19 203  20  13   9  13   3  19]\n",
      " [ 50  34  16   5   7   2   3  28  12 201  20   5   7   9   6]\n",
      " [ 66  71  14  13  11   5   5  34  18  33  84   6  17  10  10]\n",
      " [ 38   3  13   1   4   2   1   4  10   9   5 259   0   2   7]\n",
      " [ 14  13   1  27   1   7   1  14   7   7  13   2 134   5   2]\n",
      " [ 14  34  13   2   3   2   4  10   7  12  11   2   3 104   3]\n",
      " [ 47  17   7   0   4   0   1   6  31  15  10   7   3   4  53]]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'Decision Trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10846d-ec18-449c-8fd0-ac5546db0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "58e206a4-30fe-4279-a209-2dbbfbdda93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num classes:  15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.54      0.40       565\n",
      "           1       0.24      0.40      0.30       587\n",
      "           2       0.31      0.11      0.17       209\n",
      "           3       0.17      0.09      0.12       152\n",
      "           4       0.16      0.03      0.05       127\n",
      "           5       0.15      0.09      0.11       129\n",
      "           6       0.21      0.05      0.07       111\n",
      "           7       0.36      0.26      0.30       498\n",
      "           8       0.53      0.31      0.39       399\n",
      "           9       0.37      0.52      0.43       405\n",
      "          10       0.20      0.12      0.15       397\n",
      "          11       0.68      0.76      0.72       358\n",
      "          12       0.31      0.48      0.38       248\n",
      "          13       0.47      0.27      0.34       224\n",
      "          14       0.34      0.16      0.21       205\n",
      "\n",
      "    accuracy                           0.34      4614\n",
      "   macro avg       0.32      0.28      0.28      4614\n",
      "weighted avg       0.34      0.34      0.32      4614\n",
      "\n",
      "1.0\t0.0\t0.0\t0.0\n",
      "[[306  58   7   1   0   7   0  20   7  60  28  34  27   2   8]\n",
      " [106 232   6   5   4   7   5  53  18  49  36  10  37  15   4]\n",
      " [ 55  47  24   4   5   3   1   8   5  23  11  10   6   5   2]\n",
      " [ 18  33   1  14   1   2   0   7   4  11   7   1  49   3   1]\n",
      " [ 21  32   1   3   4   6   0  10   8   9  12   4   9   6   2]\n",
      " [ 27  38   1   4   1  11   0  10   5   5   4   9  10   1   3]\n",
      " [ 23  33   0   3   0   3   5  12   2   7  12   1   7   2   1]\n",
      " [ 78 134   3   6   3   5   6 127  15  40  17   9  48   6   1]\n",
      " [ 56  73   7   6   0  13   1  15 125  33  14  11  21   7  17]\n",
      " [ 58  54   6   3   1   0   1  21   7 209  12   8  14   8   3]\n",
      " [ 97 103   6   9   2   1   2  27  10  48  49  14  19   3   7]\n",
      " [ 26  18   4   0   0   2   1   5   6  12   3 272   2   2   5]\n",
      " [ 22  27   3  18   3   3   0  11   2  14  14   6 119   4   2]\n",
      " [ 37  46   2   3   0   4   2  17   2  19  17   0   8  60   7]\n",
      " [ 51  26   7   1   1   5   0   9  18  27   8  11   4   5  32]]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\delph\\anaconda3\\envs\\pytorchenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "clf = model(xTrain, yTrain, xDev, yDev, method = 'KNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458740cf-1be1-45a0-b9ec-1f5de5ccca4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
